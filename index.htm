<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Reza Azad, Azad Reza, Azad, MILA, Sharif University of Technology, ETS Montreal, Computer, Vision, Machine, Learning, Medical Image, Healthcare"> 
<meta name="description" content="Reza Azad is a deep learning researcher in medical image analysis">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Reza Azad Homepage</title>

<style>
	h1 { padding : 0; margin : 0; }
	body { padding : 20px 0; font-family : Arial; font-size : 16px; background-color : rgb(180, 180, 180); } /* background-image : url('images/bg.png');}*/

    /* #container { width : 800px; margin : 0 auto; background-color : #fff; padding : 50px;  text-align: left;} */

    #me { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0; margin-right:25px;}
    #content { display : block; margin-right : 275px;}
    a { text-decoration : none; }
    a:hover { text-decoration : underline; }
    a:visited { color : blue; }
    a.invisible { color : inherit; text-decoration : inherit; }
    .publogo { margin-right : 10px; float : left; border : 0; width: 115px; vertical-align: middle;}
	
    .publication { clear : left; padding-bottom : 10px;}
    .codelogo { margin-right : 10px; float : left; border : 0;}
    .code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
    .code .download a { display : block; margin : 0 15px; float : left;}
    #simpsons { margin : 5px auto; text-align : center; color : #B7B7B7; }
	</style>
</head>
<body>

<nav class="navbar navbar-dark navbar-expand-lg fixed-top">
    <div id="layout-menu">
        <a href="#">Home</a>
        <a href="#experience">Experience</a>
        <a href="#publications">Publications</a>
        <a href="#awards">Honors & Awards  </a>
    </div>
</nav>

<div id="layout-content" style="margin-top:25px">
 <a href="../https@github.com/rezazad68" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Reza Azad</h1><h1>
				</h1></div>

				<h3>Deep Learning Researcher & founder of Bmdeep </h3>
				<p>
					LFB RWTH <br>
					Department of Electrical Engineering<br>
					RWTH University <br>
					Aachen, Germany<br>
					<br>
					Email: rezazad68@gmail.com
			
				</p>
				<p> <a href="https://scholar.google.com/citations?hl=en&user=Qb5ildMAAAAJ&view_op=list_works&sortby=pubdate"><img src="pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/rezazad68"><img src="pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://www.linkedin.com/in/reza-azad-37a652109/"><img src="pic/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
				</p>
			</td>
			<td>
				<img src="pic/me.jpeg" border="0" width="200"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
I am a self-motivated and goal-oriented deep learning researcher on the intersection of machine learning, computer vision and medical image analysis. My ultimate research purpose is to mimic human intelligence and design intelligent algorithms to cope with challenges in the medical domain. I have a primary focus on the following topics: 
<br>
1- Few-shot learning for medical image analysis <br>
2- Texture and Inductive bias in CNN networks <br>
3- Transformers for medical image segmentation <br>
4- Minimizing human supervision (self-supervised, semi-supervised and multi-modality learning) along with robust algorithms to tackle the problem of missing labels, modalities and imperfect medical data. <br>
5- Read-world challenges for medical image analysis including Kaggle and Grand-challenge 
	</p>
	
<p>	
	Before joining RWTH, I was a research internship at MILA/NeuroPoly and ETS University, Montreal </a>, working with Prof. <a href="https://scholar.google.fr/citations?user=yHQIFFMAAAAJ&hl=en">Jose Dolz</a>. 
	I obtained my M.Sc. degree under supervision of <a href="http://sharif.edu/~kasaei/">Professor Shohreh Kasaei</a>, <a href="http://www.en.sharif.edu/">Sharif University of Technology</a> in September 2017. 
</p>


<p style="color:red;">
	I am always open to research collaboration. So if you are interested in healthcare, machine learning, computer vision, and medical image processing, feel free to drop me an email with your CV and the potential topic to discuss further. I am also looking for self-motivated researchers who have a passion for a grand challenge to attend. 
</p>
	
<div id="experience">
<h2>Experience</h2>
<ul>
	<li>
		<div style="float:left; text-align:left">RWTH University, Aachen, Germany</div> <div style="float:right; text-align:right">2021-2022</div><br>
		Research Fellow<br>
		Topic: Medical Image Analysis using Deep Learning
	</li>
	<li>
		<div style="float:left; text-align:left">MILA/NeuroPoly, deep learning for medical imaging research group, Montreal, Canada </div> <div style="float:right; text-align:right">2020 â€“ 2021</div><br>
		Applied Research Intern<br>
		Topic: Intervertebral Disc Labeling using Deep Learning <br>
	</li>
	<li>
		<div style="float:left; text-align:left">ETS, Montreal, Canada</div> <div style="float:right; text-align:right">2019. 2020</div><br>
		Research Intern<br>
		Topic: Few-shot learning <br>
	</li>
	<li>
		<div style="float:left; text-align:left">Sharif University of Technology, Tehran, Iran</div> <div style="float:right; text-align:right">2015. 2017</div><br>
		Master of AI<br>
		Topic: Human Action Recognition <br>
	</li>
</ul>
<br>
</div>





<!-- 


In this part new publication code is added

 -->
 <script async="" src="index_files/analytics.js"></script><script type="text/javascript">
	<!--
	function popup(mylink, windowname)
	{
	if (! window.focus)return true;
	var href;
	if (typeof(mylink) == 'string')
	   href=mylink;
	else
	   href=mylink.href;
	window.open(href, windowname, 'width=800,height=300,scrollbars=yes,menubar=no');
	return false;
	}
	//-->
	</script>


	<!-- <div id="container"> -->
		<div id="publications">
			<h2>Selected Publications [<a href="../https@scholar.google.com/citations@user=llXf3wUAAAAJ&hl=en">Google Scholar</a>]</h2>
  <table border="0" cellpadding="0" cellspacing="0" width="900" align="center" bgcolor="#FFFFFF">

  <tbody>
	
	  
<!-- frcunet Paper  -->

	<tr>
    <td>
      <a href="papers/frcunet.pdf"><img border="0" src="index_files/frcunet.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Deep Frequency Re-Calibration U-Net for Medical Image Segmentatio</strong>
    <br>Reza Azad, Afshin Bozorgpour, Maryam Asadi-Aghbolaghi, Dorit Merhof, Sergio Escalera<br>
		<em>International Conference on Computer Vision (ICCV) 2021 (Oral presentation).</em><br>
		<a href="papers/frcunet.pdf">[PDF]</a> 
		<a href="https://openaccess.thecvf.com/content/ICCV2021W/CVAMD/html/Azad_Deep_Frequency_Re-Calibration_U-Net_for_Medical_Image_Segmentation_ICCVW_2021_paper.html">[Project page]</a>
        <a href="https://github.com/rezazad68/FRCU-Net">[Code]</a>
      </p></div>
    </td>
  </tr> 
	  
	  
<!-- intervertebral disc Paper  -->

	<tr>
    <td>
      <a href="papers/vertebra.pdf"><img border="0" src="index_files/vertebra.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Stacked Hourglass Network with a Multi-level Attention Mechanism: Where to Look for Intervertebral Disc Labeling</strong>
    <br>Reza Azad, Lucas Rouhier, and Julien Cohen-Adad<br>
		<em>Proceedings of the MICCAI Workshop on MLMI, 2021.</em><br>
		<a href="papers/vertebra.pdf">[PDF]</a> 
		<a href="https://link.springer.com/chapter/10.1007/978-3-030-87589-3_42">[Project page]</a>
        <a href="https://github.com/rezazad68/Deep-Intervertebral-Disc-Labeling">[Code]</a>
      </p></div>
    </td>
  </tr> 
	  
	  
<!-- segpc Paper  -->

	<tr>
    <td>
      <a href="papers/segpc.pdf"><img border="0" src="index_files/segpc.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Multi-scale Regional Attention Deeplab3+: Multiple Myeloma Plasma Cells Segmentation in Microscopic Images</strong>
    <br>Afshin Bozorgpour*, Reza Azad*, Showkatian Eman, Sulaiman Alaa<br>
    <small>*equal contribution</small><br>
		<em>Proceedings of the MICCAI Workshop on Computational Pathology, PMLR 156:47-56, 2021 (Oral presentation).</em><br>
		<a href="papers/segpc.pdf">[PDF]</a> 
		<a href="https://proceedings.mlr.press/v156/afshin21a/afshin21a.pdf">[Project page]</a>
        <a href="https://github.com/bmdeep/SegPC2021">[Code]</a>
      </p></div>
    </td>
  </tr> 
	  
	  
<!-- Texture bias Paper  -->

	<tr>
    <td>
      <a href="papers/texturebias.pdf"><img border="0" src="index_files/texturebias.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>On the texture bias for few-shot cnn segmentation</strong>
    <br>Reza Azad, Abdur R Fayjie, Claude Kauffmann, Ismail Ben Ayed, Marco Pedersoli, Jose Dolz<br>
		<em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2021 (Oral presentation).</em><br>
		<a href="papers/texturebias.pdf">[PDF]</a> 
		<a href="https://openaccess.thecvf.com/content/WACV2021/html/Azad_On_the_Texture_Bias_for_Few-Shot_CNN_Segmentation_WACV_2021_paper.html">[Project page]</a>
        <a href="https://github.com/rezazad68/fewshot-segmentation">[Code]</a>
      </p></div>
    </td>
  </tr> 
	  
	  
<!-- Attention deeplab Paper  -->

	<tr>
    <td>
      <a href="papers/attentiondeeplab.pdf"><img border="0" src="index_files/attentiondeeplab.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Attention Deeplabv3+: Multi-level Context Attention Mechanism for Skin Lesion Segmentation</strong>
    <br>Reza Azad, Maryam Asadi, Mahmood Fathy and Sergio Escalera<br>
		<em>European Conference on Computer Vision (ECCV), 2020.</em><br>
		<a href="papers/attentiondeeplab.pdf">[PDF]</a> 
		<a href="https://link.springer.com/chapter/10.1007/978-3-030-66415-2_16">[Project page]</a>
        <a href="https://github.com/rezazad68/AttentionDeeplabv3p">[Code]</a>
      </p></div>
    </td>
  </tr> 
	  
	  
<!-- med_fewshot Paper  -->

	<tr>
    <td>
      <a href="papers/med_fewshot.pdf"><img border="0" src="index_files/med_fewshot.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Semi-supervised few-shot learning for medical image segmentation</strong>
    <br>Abdur R Feyjie, Reza Azad, Marco Pedersoli, Claude Kauffman, Ismail Ben Ayed, Jose Dolz<br>
		<em>arXiv preprint arXiv:2003.08462, 2020.</em><br>
		<a href="papers/med_fewshot.pdf">[PDF]</a> 
		<a href="https://arxiv.org/pdf/2003.08462.pdf">[Project page]</a>
        <a href="https://github.com/fayjie92/FSMS-Surrogate">[Code]</a>
      </p></div>
    </td>
  </tr> 
	  
	  
<!-- bcd_extend-Net Paper  -->

	<tr>
    <td>
      <a href="papers/bcd_extend.pdf"><img border="0" src="index_files/bcd_extend.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Multi-level Context Gating of Embedded Collective Knowledge for Medical Image Segmentation</strong>
    <br>Reza Azad, Maryam Asadi, Mahmood Fathy and Sergio Escalera<br>
		<em>arXiv:2003.05056, 2020.</em><br>
		<a href="papers/bcd_extend.pdf">[PDF]</a> 
		<a href="https://arxiv.org/pdf/2003.05056.pdf">[Project page]</a>
        <a href="https://github.com/rezazad68/BCDU-Net">[Code]</a>
      </p></div>
    </td>
  </tr> 

	  
	  
	  
	  
<!-- BCDU-Net Paper  -->

	<tr>
    <td>
      <a href="papers/bcdunet.pdf"><img border="0" src="index_files/bcdunet.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Bi-Directional ConvLSTM U-Net with Densely Connected Convolutions</strong>
    <br>Reza Azad, Maryam Asadi, Mahmood Fathy and Sergio Escalera<br>
		<em>International Conference on Computer Vision (ICCV) 2019 (Oral presentation).</em><br>
		<a href="papers/bcdunet.pdf">[PDF]</a> 
		<a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/VRMI/Azad_Bi-Directional_ConvLSTM_U-Net_with_Densley_Connected_Convolutions_ICCVW_2019_paper.pdf">[Project page]</a>
        <a href="https://github.com/rezazad68/BCDU-Net">[Code]</a>
      </p></div>
    </td>
  </tr> 

<!-- Action 3D Paper  -->

	<tr>
    <td>
      <a href="papers/action_wdmm.pdf"><img border="0" src="index_files/action_wdmm.png" class="publogo"> 
    </a></td>
    <td>
      <div class="publication">
      <p><strong>Dynamic 3D Hand Gesture Recognition by Learning Weighted Depth Motion Maps</strong>
    <br>Reza Azad, Maryam Asadi, Shohreh Kasaei and Sergio Escalera<br>
		<em>IEEE Transactions on Circuits and Systems for Video Technology, Volume: 29, Issue: 6, June 2019.</em><br>
		<a href="papers/action_wdmm.pdf">[PDF]</a> 
		<a href="https://ieeexplore.ieee.org/abstract/document/8410578">[Project page]</a>
        <a href="https://github.com/rezazad68/Dynamic-3D-Action-Recognition-on-RGB-D-Videos">[Code]</a>
      </p></div>
    </td>
  </tr> 	  


</tbody>
</table>
</div>


	
	<!-- 

		End of the new publication code

	 -->


<br>


<div id="awards">
<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	
		<tbody>
		<tr><td>IEEE journal reviewer, 2021 </td></tr>
		<tr><td>Second place in SegPC grand challenge. <a href="https://segpc-2021.grand-challenge.org/">SegPC 2021 ISBI  Challenge</a> </td></tr>
		<tr><td>Invited speaker at the fourth IPM advanced school on computing 2020. <a href="http://cs.ipm.ac.ir/asoc2020/">IPM event</a> </td></tr>	
                 
	</tbody>
</table>
<br>
</div>




</div>
</body></html>
